{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SA in Bengali Language Using BERT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN3vMsVjdvbgq6a7yqkEiqg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shakilB/Projects/blob/main/SA_in_Bengali_Language_Using_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zF1WKAKa-ZX",
        "outputId": "32437f7f-9b3d-4cd1-ef72-66469ca98e06"
      },
      "source": [
        "!pip install ktrain"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ktrain in /usr/local/lib/python3.7/dist-packages (0.28.3)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from ktrain) (0.1.96)\n",
            "Requirement already satisfied: fastprogress>=0.1.21 in /usr/local/lib/python3.7/dist-packages (from ktrain) (1.0.0)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from ktrain) (1.1.5)\n",
            "Requirement already satisfied: syntok in /usr/local/lib/python3.7/dist-packages (from ktrain) (1.3.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ktrain) (2.23.0)\n",
            "Requirement already satisfied: keras-bert>=0.86.0 in /usr/local/lib/python3.7/dist-packages (from ktrain) (0.88.0)\n",
            "Requirement already satisfied: whoosh in /usr/local/lib/python3.7/dist-packages (from ktrain) (2.7.4)\n",
            "Requirement already satisfied: transformers<=4.10.3,>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from ktrain) (4.10.3)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.7/dist-packages (from ktrain) (3.0.4)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.7/dist-packages (from ktrain) (1.0.9)\n",
            "Requirement already satisfied: cchardet in /usr/local/lib/python3.7/dist-packages (from ktrain) (2.1.7)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.7/dist-packages (from ktrain) (0.42.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from ktrain) (21.3)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from ktrain) (3.2.2)\n",
            "Requirement already satisfied: scikit-learn==0.23.2 in /usr/local/lib/python3.7/dist-packages (from ktrain) (0.23.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from ktrain) (1.1.0)\n",
            "Requirement already satisfied: seqeval==0.0.19 in /usr/local/lib/python3.7/dist-packages (from ktrain) (0.0.19)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.2->ktrain) (3.0.0)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.2->ktrain) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.23.2->ktrain) (1.19.5)\n",
            "Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.7/dist-packages (from seqeval==0.0.19->ktrain) (2.7.0)\n",
            "Requirement already satisfied: keras-transformer>=0.39.0 in /usr/local/lib/python3.7/dist-packages (from keras-bert>=0.86.0->ktrain) (0.39.0)\n",
            "Requirement already satisfied: keras-layer-normalization>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from keras-transformer>=0.39.0->keras-bert>=0.86.0->ktrain) (0.15.0)\n",
            "Requirement already satisfied: keras-pos-embd>=0.12.0 in /usr/local/lib/python3.7/dist-packages (from keras-transformer>=0.39.0->keras-bert>=0.86.0->ktrain) (0.12.0)\n",
            "Requirement already satisfied: keras-multi-head>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from keras-transformer>=0.39.0->keras-bert>=0.86.0->ktrain) (0.28.0)\n",
            "Requirement already satisfied: keras-position-wise-feed-forward>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from keras-transformer>=0.39.0->keras-bert>=0.86.0->ktrain) (0.7.0)\n",
            "Requirement already satisfied: keras-embed-sim>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from keras-transformer>=0.39.0->keras-bert>=0.86.0->ktrain) (0.9.0)\n",
            "Requirement already satisfied: keras-self-attention>=0.50.0 in /usr/local/lib/python3.7/dist-packages (from keras-multi-head>=0.28.0->keras-transformer>=0.39.0->keras-bert>=0.86.0->ktrain) (0.50.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->ktrain) (0.11.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->ktrain) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->ktrain) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.0.0->ktrain) (3.0.6)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.0.1->ktrain) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=3.0.0->ktrain) (1.15.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers<=4.10.3,>=4.0.0->ktrain) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<=4.10.3,>=4.0.0->ktrain) (3.4.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers<=4.10.3,>=4.0.0->ktrain) (0.10.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<=4.10.3,>=4.0.0->ktrain) (0.0.46)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<=4.10.3,>=4.0.0->ktrain) (4.8.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers<=4.10.3,>=4.0.0->ktrain) (4.62.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers<=4.10.3,>=4.0.0->ktrain) (0.1.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<=4.10.3,>=4.0.0->ktrain) (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.12->transformers<=4.10.3,>=4.0.0->ktrain) (3.10.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<=4.10.3,>=4.0.0->ktrain) (3.6.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ktrain) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->ktrain) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ktrain) (2021.10.8)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<=4.10.3,>=4.0.0->ktrain) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0tJEdqlbNZP"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import ktrain\n",
        "\n",
        "from ktrain import text\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJpLBfsRbuvI"
      },
      "source": [
        "data = pd.read_csv('/content/finaldataset.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2W9gelVb_H8",
        "outputId": "c8687344-6d10-449b-8e52-3f6cc90e87ea"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13802, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "UgIr85NJcDJ1",
        "outputId": "71f2e9bc-b040-4606-8ec2-a7db929579d9"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>title_x</th>\n",
              "      <th>title_y</th>\n",
              "      <th>title</th>\n",
              "      <th>value</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>লিখার সময় পারলে সত্য লিখার অভ্যাস শিখুন।</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>2</td>\n",
              "      <td>-1</td>\n",
              "      <td>কিছুটা নেতিবাচক</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>এটা কেন হচ্ছে? সংশ্লিষ্ট সকলের ডিপ্রেশনের ফলে?...</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>কিছুটা নেতিবাচক</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>আমাদের দেশের স্বাভাবিক অর্থনৈতিক গতিপ্রবাহকে ব...</td>\n",
              "      <td>-1</td>\n",
              "      <td>-2</td>\n",
              "      <td>-2</td>\n",
              "      <td>-5</td>\n",
              "      <td>নিশ্চিত নেতিবাচক</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>চুরি নয় লুটপাট।</td>\n",
              "      <td>-2</td>\n",
              "      <td>-2</td>\n",
              "      <td>-2</td>\n",
              "      <td>-6</td>\n",
              "      <td>নিশ্চিত নেতিবাচক</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ইসলামী ব্যাংকের বর্তমান অবস্থা দেখে মনে হয় শাস...</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>নিরপেক্ষ</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                data  ...               tag\n",
              "0           লিখার সময় পারলে সত্য লিখার অভ্যাস শিখুন।  ...   কিছুটা নেতিবাচক\n",
              "1  এটা কেন হচ্ছে? সংশ্লিষ্ট সকলের ডিপ্রেশনের ফলে?...  ...   কিছুটা নেতিবাচক\n",
              "2  আমাদের দেশের স্বাভাবিক অর্থনৈতিক গতিপ্রবাহকে ব...  ...  নিশ্চিত নেতিবাচক\n",
              "3                                    চুরি নয় লুটপাট।  ...  নিশ্চিত নেতিবাচক\n",
              "4  ইসলামী ব্যাংকের বর্তমান অবস্থা দেখে মনে হয় শাস...  ...          নিরপেক্ষ\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsKszixEHFMx"
      },
      "source": [
        "data.drop(['title_x','title_y','title','value'],axis=1,inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ofO7DITeICg2",
        "outputId": "c88ef551-0b59-4b4e-c917-3959407ccd79"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>লিখার সময় পারলে সত্য লিখার অভ্যাস শিখুন।</td>\n",
              "      <td>কিছুটা নেতিবাচক</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>এটা কেন হচ্ছে? সংশ্লিষ্ট সকলের ডিপ্রেশনের ফলে?...</td>\n",
              "      <td>কিছুটা নেতিবাচক</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>আমাদের দেশের স্বাভাবিক অর্থনৈতিক গতিপ্রবাহকে ব...</td>\n",
              "      <td>নিশ্চিত নেতিবাচক</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>চুরি নয় লুটপাট।</td>\n",
              "      <td>নিশ্চিত নেতিবাচক</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ইসলামী ব্যাংকের বর্তমান অবস্থা দেখে মনে হয় শাস...</td>\n",
              "      <td>নিরপেক্ষ</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                data               tag\n",
              "0           লিখার সময় পারলে সত্য লিখার অভ্যাস শিখুন।   কিছুটা নেতিবাচক\n",
              "1  এটা কেন হচ্ছে? সংশ্লিষ্ট সকলের ডিপ্রেশনের ফলে?...   কিছুটা নেতিবাচক\n",
              "2  আমাদের দেশের স্বাভাবিক অর্থনৈতিক গতিপ্রবাহকে ব...  নিশ্চিত নেতিবাচক\n",
              "3                                    চুরি নয় লুটপাট।  নিশ্চিত নেতিবাচক\n",
              "4  ইসলামী ব্যাংকের বর্তমান অবস্থা দেখে মনে হয় শাস...          নিরপেক্ষ"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6C18gN6IHU4",
        "outputId": "83fc2fe0-8709-451b-8072-2dd6726e0731"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13802, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "jH4cCBN1cI9M",
        "outputId": "1045804a-a571-41ae-d884-05b95a5e4db7"
      },
      "source": [
        "data.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>13802</td>\n",
              "      <td>13802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>13542</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>গনতন্ত্র শক্তিশালী না হলে দেশ লুটপাট হয়ে যাবে,...</td>\n",
              "      <td>নিশ্চিত নেতিবাচক</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>2</td>\n",
              "      <td>3928</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     data               tag\n",
              "count                                               13802             13802\n",
              "unique                                              13542                 5\n",
              "top     গনতন্ত্র শক্তিশালী না হলে দেশ লুটপাট হয়ে যাবে,...  নিশ্চিত নেতিবাচক\n",
              "freq                                                    2              3928"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8gSC4RWdApE",
        "outputId": "3af83a8f-2b63-4c6f-8391-ea0c20a85b6d"
      },
      "source": [
        "data.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "data    0\n",
              "tag     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z_Fdc6B7dcdF",
        "outputId": "abc7fa16-44ed-4d57-f5ba-17861b243548"
      },
      "source": [
        "data.tag.unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['কিছুটা নেতিবাচক', 'নিশ্চিত নেতিবাচক', 'নিরপেক্ষ',\n",
              "       'কিছুটা ইতিবাচক', 'নিশ্চিত ইতিবাচক'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLXeKxNZIX3C"
      },
      "source": [
        "data.loc[(data.tag == 'কিছুটা নেতিবাচক'),'label']=1\n",
        "data.loc[(data.tag == 'নিশ্চিত নেতিবাচক'),'label']=1\n",
        "data.loc[(data.tag == 'নিরপেক্ষ'),'label']=0\n",
        "data.loc[(data.tag == 'কিছুটা ইতিবাচক'),'label']=2\n",
        "data.loc[(data.tag == 'নিশ্চিত ইতিবাচক'),'label']=2\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMegU0FdeSGF"
      },
      "source": [
        "data['label'] = data['label'].apply(np.int64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCFJXUoleUjF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "b3c60fe0-2e8e-4c1a-a0e4-220f00c4a253"
      },
      "source": [
        "data.sample(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>tag</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10394</th>\n",
              "      <td>@রনি-আরিফ@দোষ রিপোর্টারকে দিয়ে লাভ কি সাম্পাওল...</td>\n",
              "      <td>নিরপেক্ষ</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2926</th>\n",
              "      <td>ভেবেছিল প্রতিবাদী অন্য সৌদি নাগরিকদের যেভাবে '...</td>\n",
              "      <td>নিশ্চিত নেতিবাচক</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9833</th>\n",
              "      <td>আশরাফুল আমার ফেবারিট</td>\n",
              "      <td>নিশ্চিত ইতিবাচক</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10066</th>\n",
              "      <td>পাকিস্তানের কপালে সেই ভাগ্য কি আর কখনো হবে?  আ...</td>\n",
              "      <td>কিছুটা নেতিবাচক</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5959</th>\n",
              "      <td>আপনাদের পক্ষে তো কেউই নাই, কি করবেন এখন!</td>\n",
              "      <td>কিছুটা নেতিবাচক</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9204</th>\n",
              "      <td>পাকিস্তান চিন দেশে গাধা রপ্তানি করে বিদেশি মুদ...</td>\n",
              "      <td>নিরপেক্ষ</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9414</th>\n",
              "      <td>ও যে এগোচ্ছে তাতে সেন্চুরির সেন্চুরি অবশ্যই হবে।</td>\n",
              "      <td>নিশ্চিত ইতিবাচক</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11281</th>\n",
              "      <td>সিরিজ হারা ঠেকাতে কী করতে হবে বাংলাদেশকে? বেশি...</td>\n",
              "      <td>নিশ্চিত নেতিবাচক</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5833</th>\n",
              "      <td>কেউ আমাকে অনুগ্রহ করে একটু বলবেন কি যে সরকারি ...</td>\n",
              "      <td>কিছুটা নেতিবাচক</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1437</th>\n",
              "      <td>ইসলামী ব্যাংকে গিলতে গিয়ে তা এখন এমন এক জায়গায়...</td>\n",
              "      <td>নিশ্চিত নেতিবাচক</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    data  ... label\n",
              "10394  @রনি-আরিফ@দোষ রিপোর্টারকে দিয়ে লাভ কি সাম্পাওল...  ...   0.0\n",
              "2926   ভেবেছিল প্রতিবাদী অন্য সৌদি নাগরিকদের যেভাবে '...  ...   1.0\n",
              "9833                                আশরাফুল আমার ফেবারিট  ...   2.0\n",
              "10066  পাকিস্তানের কপালে সেই ভাগ্য কি আর কখনো হবে?  আ...  ...   1.0\n",
              "5959            আপনাদের পক্ষে তো কেউই নাই, কি করবেন এখন!  ...   1.0\n",
              "9204   পাকিস্তান চিন দেশে গাধা রপ্তানি করে বিদেশি মুদ...  ...   0.0\n",
              "9414    ও যে এগোচ্ছে তাতে সেন্চুরির সেন্চুরি অবশ্যই হবে।  ...   2.0\n",
              "11281  সিরিজ হারা ঠেকাতে কী করতে হবে বাংলাদেশকে? বেশি...  ...   1.0\n",
              "5833   কেউ আমাকে অনুগ্রহ করে একটু বলবেন কি যে সরকারি ...  ...   1.0\n",
              "1437   ইসলামী ব্যাংকে গিলতে গিয়ে তা এখন এমন এক জায়গায়...  ...   1.0\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "P7OLyAUxe9Xt",
        "outputId": "94c645c0-82ca-45b1-8f1b-8d75b1cd9a27"
      },
      "source": [
        "tmp =  data['label'].value_counts().sort_index()\n",
        "import seaborn as sb\n",
        "sb.countplot(x='label' , data = data , order = tmp.index)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f01d67e90d0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8yy2XsUyJC_"
      },
      "source": [
        "from sklearn.utils import class_weight"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18wDjL_GJI4t",
        "outputId": "c87faf84-aa83-4278-bbf6-761a570ed682"
      },
      "source": [
        "data.label"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        1.0\n",
              "1        1.0\n",
              "2        1.0\n",
              "3        1.0\n",
              "4        0.0\n",
              "        ... \n",
              "13797    0.0\n",
              "13798    0.0\n",
              "13799    0.0\n",
              "13800    0.0\n",
              "13801    0.0\n",
              "Name: label, Length: 13802, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUMNWg50JNJX"
      },
      "source": [
        "new_df = data.loc[: , ['data' , 'label']] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "go5SyToHJTjF",
        "outputId": "641e1469-fa1f-448c-8377-eba4abb72146"
      },
      "source": [
        "new_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>লিখার সময় পারলে সত্য লিখার অভ্যাস শিখুন।</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>এটা কেন হচ্ছে? সংশ্লিষ্ট সকলের ডিপ্রেশনের ফলে?...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>আমাদের দেশের স্বাভাবিক অর্থনৈতিক গতিপ্রবাহকে ব...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>চুরি নয় লুটপাট।</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ইসলামী ব্যাংকের বর্তমান অবস্থা দেখে মনে হয় শাস...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                data  label\n",
              "0           লিখার সময় পারলে সত্য লিখার অভ্যাস শিখুন।    1.0\n",
              "1  এটা কেন হচ্ছে? সংশ্লিষ্ট সকলের ডিপ্রেশনের ফলে?...    1.0\n",
              "2  আমাদের দেশের স্বাভাবিক অর্থনৈতিক গতিপ্রবাহকে ব...    1.0\n",
              "3                                    চুরি নয় লুটপাট।    1.0\n",
              "4  ইসলামী ব্যাংকের বর্তমান অবস্থা দেখে মনে হয় শাস...    0.0"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxxP_lTpymz9",
        "outputId": "503382e4-ad62-4623-b6fa-af3fe043ca14"
      },
      "source": [
        "class_weights = list(class_weight.compute_class_weight(\n",
        "                                        class_weight = \"balanced\",\n",
        "                                        classes = np.unique(new_df['label']),\n",
        "                                        y = new_df['label']                                                    \n",
        "                                    ))\n",
        "weights = dict(zip(np.unique(new_df['label']), class_weights))\n",
        "weights"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0.0: 1.559019541398396, 1.0: 0.6456169894283843, 2.0: 1.2350782997762864}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwU0LxyiJYWL"
      },
      "source": [
        "train_data = new_df.iloc[0:9661][:]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0eqIooaJgj-",
        "outputId": "a98f57f1-6bf1-4b93-8d9c-11830dc5b1bb"
      },
      "source": [
        "train_data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9661, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NqaoUAyJmYT"
      },
      "source": [
        "test_data = new_df.iloc[9661:][:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Av5qkhfJq5w",
        "outputId": "f6d577e5-1a7a-4ee1-d541-8044fede6a64"
      },
      "source": [
        "test_data.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4141, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "id": "QtQDpPQUfYKs",
        "outputId": "5d0f5066-4cea-49ba-fa89-ab5ac0732d63"
      },
      "source": [
        "(X_train, y_train), (X_test , y_test) , preproc = text.texts_from_df(train_df= new_df,\n",
        "                                                                     text_column = 'data',\n",
        "                                                                     label_columns = 'label',\n",
        "                                                                     maxlen=512,\n",
        "                                                                     preprocess_mode = 'bert'\n",
        "                                                                     )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ktrain/utils.py:637: UserWarning: class_names implies classification but targets array contains float(s) instead of integers or strings\n",
            "  warnings.warn('class_names implies classification but targets array contains float(s) instead of integers or strings')\n",
            "/usr/local/lib/python3.7/dist-packages/ktrain/utils.py:637: UserWarning: class_names implies classification but targets array contains float(s) instead of integers or strings\n",
            "  warnings.warn('class_names implies classification but targets array contains float(s) instead of integers or strings')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['label_0.0', 'label_1.0', 'label_2.0']\n",
            "       label_0.0  label_1.0  label_2.0\n",
            "1153         0.0        0.0        1.0\n",
            "6631         0.0        0.0        1.0\n",
            "2386         0.0        1.0        0.0\n",
            "12189        0.0        1.0        0.0\n",
            "10507        1.0        0.0        0.0\n",
            "['label_0.0', 'label_1.0', 'label_2.0']\n",
            "       label_0.0  label_1.0  label_2.0\n",
            "11484        0.0        1.0        0.0\n",
            "400          1.0        0.0        0.0\n",
            "8295         0.0        1.0        0.0\n",
            "9840         1.0        0.0        0.0\n",
            "7816         0.0        1.0        0.0\n",
            "preprocessing train...\n",
            "language: bn\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "done."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is Multi-Label? False\n",
            "preprocessing test...\n",
            "language: bn\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "done."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n95EEXR-KzJ-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4mqioQpfs91",
        "outputId": "9e8fc265-f27f-440f-f747-087c69105a6a"
      },
      "source": [
        "model = text.text_classifier(name='bert',\n",
        "                             train_data = (X_train ,y_train),\n",
        "                             preproc= preproc)\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is Multi-Label? False\n",
            "maxlen is 512\n",
            "done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21QnRd7R81Eo",
        "outputId": "757de5a3-ed78-4fce-9903-a9c9d4bc57a3"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " Input-Token (InputLayer)       [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " Input-Segment (InputLayer)     [(None, 512)]        0           []                               \n",
            "                                                                                                  \n",
            " Embedding-Token (TokenEmbeddin  [(None, 512, 768),  91812096    ['Input-Token[0][0]']            \n",
            " g)                              (119547, 768)]                                                   \n",
            "                                                                                                  \n",
            " Embedding-Segment (Embedding)  (None, 512, 768)     1536        ['Input-Segment[0][0]']          \n",
            "                                                                                                  \n",
            " Embedding-Token-Segment (Add)  (None, 512, 768)     0           ['Embedding-Token[0][0]',        \n",
            "                                                                  'Embedding-Segment[0][0]']      \n",
            "                                                                                                  \n",
            " Embedding-Position (PositionEm  (None, 512, 768)    393216      ['Embedding-Token-Segment[0][0]']\n",
            " bedding)                                                                                         \n",
            "                                                                                                  \n",
            " Embedding-Dropout (Dropout)    (None, 512, 768)     0           ['Embedding-Position[0][0]']     \n",
            "                                                                                                  \n",
            " Embedding-Norm (LayerNormaliza  (None, 512, 768)    1536        ['Embedding-Dropout[0][0]']      \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " Encoder-1-MultiHeadSelfAttenti  (None, 512, 768)    2362368     ['Embedding-Norm[0][0]']         \n",
            " on (MultiHeadAttention)                                                                          \n",
            "                                                                                                  \n",
            " Encoder-1-MultiHeadSelfAttenti  (None, 512, 768)    0           ['Encoder-1-MultiHeadSelfAttentio\n",
            " on-Dropout (Dropout)                                            n[0][0]']                        \n",
            "                                                                                                  \n",
            " Encoder-1-MultiHeadSelfAttenti  (None, 512, 768)    0           ['Embedding-Norm[0][0]',         \n",
            " on-Add (Add)                                                     'Encoder-1-MultiHeadSelfAttentio\n",
            "                                                                 n-Dropout[0][0]']                \n",
            "                                                                                                  \n",
            " Encoder-1-MultiHeadSelfAttenti  (None, 512, 768)    1536        ['Encoder-1-MultiHeadSelfAttentio\n",
            " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
            "                                                                                                  \n",
            " Encoder-1-FeedForward (FeedFor  (None, 512, 768)    4722432     ['Encoder-1-MultiHeadSelfAttentio\n",
            " ward)                                                           n-Norm[0][0]']                   \n",
            "                                                                                                  \n",
            " Encoder-1-FeedForward-Dropout   (None, 512, 768)    0           ['Encoder-1-FeedForward[0][0]']  \n",
            " (Dropout)                                                                                        \n",
            "                                                                                                  \n",
            " Encoder-1-FeedForward-Add (Add  (None, 512, 768)    0           ['Encoder-1-MultiHeadSelfAttentio\n",
            " )                                                               n-Norm[0][0]',                   \n",
            "                                                                  'Encoder-1-FeedForward-Dropout[0\n",
            "                                                                 ][0]']                           \n",
            "                                                                                                  \n",
            " Encoder-1-FeedForward-Norm (La  (None, 512, 768)    1536        ['Encoder-1-FeedForward-Add[0][0]\n",
            " yerNormalization)                                               ']                               \n",
            "                                                                                                  \n",
            " Encoder-2-MultiHeadSelfAttenti  (None, 512, 768)    2362368     ['Encoder-1-FeedForward-Norm[0][0\n",
            " on (MultiHeadAttention)                                         ]']                              \n",
            "                                                                                                  \n",
            " Encoder-2-MultiHeadSelfAttenti  (None, 512, 768)    0           ['Encoder-2-MultiHeadSelfAttentio\n",
            " on-Dropout (Dropout)                                            n[0][0]']                        \n",
            "                                                                                                  \n",
            " Encoder-2-MultiHeadSelfAttenti  (None, 512, 768)    0           ['Encoder-1-FeedForward-Norm[0][0\n",
            " on-Add (Add)                                                    ]',                              \n",
            "                                                                  'Encoder-2-MultiHeadSelfAttentio\n",
            "                                                                 n-Dropout[0][0]']                \n",
            "                                                                                                  \n",
            " Encoder-2-MultiHeadSelfAttenti  (None, 512, 768)    1536        ['Encoder-2-MultiHeadSelfAttentio\n",
            " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
            "                                                                                                  \n",
            " Encoder-2-FeedForward (FeedFor  (None, 512, 768)    4722432     ['Encoder-2-MultiHeadSelfAttentio\n",
            " ward)                                                           n-Norm[0][0]']                   \n",
            "                                                                                                  \n",
            " Encoder-2-FeedForward-Dropout   (None, 512, 768)    0           ['Encoder-2-FeedForward[0][0]']  \n",
            " (Dropout)                                                                                        \n",
            "                                                                                                  \n",
            " Encoder-2-FeedForward-Add (Add  (None, 512, 768)    0           ['Encoder-2-MultiHeadSelfAttentio\n",
            " )                                                               n-Norm[0][0]',                   \n",
            "                                                                  'Encoder-2-FeedForward-Dropout[0\n",
            "                                                                 ][0]']                           \n",
            "                                                                                                  \n",
            " Encoder-2-FeedForward-Norm (La  (None, 512, 768)    1536        ['Encoder-2-FeedForward-Add[0][0]\n",
            " yerNormalization)                                               ']                               \n",
            "                                                                                                  \n",
            " Encoder-3-MultiHeadSelfAttenti  (None, 512, 768)    2362368     ['Encoder-2-FeedForward-Norm[0][0\n",
            " on (MultiHeadAttention)                                         ]']                              \n",
            "                                                                                                  \n",
            " Encoder-3-MultiHeadSelfAttenti  (None, 512, 768)    0           ['Encoder-3-MultiHeadSelfAttentio\n",
            " on-Dropout (Dropout)                                            n[0][0]']                        \n",
            "                                                                                                  \n",
            " Encoder-3-MultiHeadSelfAttenti  (None, 512, 768)    0           ['Encoder-2-FeedForward-Norm[0][0\n",
            " on-Add (Add)                                                    ]',                              \n",
            "                                                                  'Encoder-3-MultiHeadSelfAttentio\n",
            "                                                                 n-Dropout[0][0]']                \n",
            "                                                                                                  \n",
            " Encoder-3-MultiHeadSelfAttenti  (None, 512, 768)    1536        ['Encoder-3-MultiHeadSelfAttentio\n",
            " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
            "                                                                                                  \n",
            " Encoder-3-FeedForward (FeedFor  (None, 512, 768)    4722432     ['Encoder-3-MultiHeadSelfAttentio\n",
            " ward)                                                           n-Norm[0][0]']                   \n",
            "                                                                                                  \n",
            " Encoder-3-FeedForward-Dropout   (None, 512, 768)    0           ['Encoder-3-FeedForward[0][0]']  \n",
            " (Dropout)                                                                                        \n",
            "                                                                                                  \n",
            " Encoder-3-FeedForward-Add (Add  (None, 512, 768)    0           ['Encoder-3-MultiHeadSelfAttentio\n",
            " )                                                               n-Norm[0][0]',                   \n",
            "                                                                  'Encoder-3-FeedForward-Dropout[0\n",
            "                                                                 ][0]']                           \n",
            "                                                                                                  \n",
            " Encoder-3-FeedForward-Norm (La  (None, 512, 768)    1536        ['Encoder-3-FeedForward-Add[0][0]\n",
            " yerNormalization)                                               ']                               \n",
            "                                                                                                  \n",
            " Encoder-4-MultiHeadSelfAttenti  (None, 512, 768)    2362368     ['Encoder-3-FeedForward-Norm[0][0\n",
            " on (MultiHeadAttention)                                         ]']                              \n",
            "                                                                                                  \n",
            " Encoder-4-MultiHeadSelfAttenti  (None, 512, 768)    0           ['Encoder-4-MultiHeadSelfAttentio\n",
            " on-Dropout (Dropout)                                            n[0][0]']                        \n",
            "                                                                                                  \n",
            " Encoder-4-MultiHeadSelfAttenti  (None, 512, 768)    0           ['Encoder-3-FeedForward-Norm[0][0\n",
            " on-Add (Add)                                                    ]',                              \n",
            "                                                                  'Encoder-4-MultiHeadSelfAttentio\n",
            "                                                                 n-Dropout[0][0]']                \n",
            "                                                                                                  \n",
            " Encoder-4-MultiHeadSelfAttenti  (None, 512, 768)    1536        ['Encoder-4-MultiHeadSelfAttentio\n",
            " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
            "                                                                                                  \n",
            " Encoder-4-FeedForward (FeedFor  (None, 512, 768)    4722432     ['Encoder-4-MultiHeadSelfAttentio\n",
            " ward)                                                           n-Norm[0][0]']                   \n",
            "                                                                                                  \n",
            " Encoder-4-FeedForward-Dropout   (None, 512, 768)    0           ['Encoder-4-FeedForward[0][0]']  \n",
            " (Dropout)                                                                                        \n",
            "                                                                                                  \n",
            " Encoder-4-FeedForward-Add (Add  (None, 512, 768)    0           ['Encoder-4-MultiHeadSelfAttentio\n",
            " )                                                               n-Norm[0][0]',                   \n",
            "                                                                  'Encoder-4-FeedForward-Dropout[0\n",
            "                                                                 ][0]']                           \n",
            "                                                                                                  \n",
            " Encoder-4-FeedForward-Norm (La  (None, 512, 768)    1536        ['Encoder-4-FeedForward-Add[0][0]\n",
            " yerNormalization)                                               ']                               \n",
            "                                                                                                  \n",
            " Encoder-5-MultiHeadSelfAttenti  (None, 512, 768)    2362368     ['Encoder-4-FeedForward-Norm[0][0\n",
            " on (MultiHeadAttention)                                         ]']                              \n",
            "                                                                                                  \n",
            " Encoder-5-MultiHeadSelfAttenti  (None, 512, 768)    0           ['Encoder-5-MultiHeadSelfAttentio\n",
            " on-Dropout (Dropout)                                            n[0][0]']                        \n",
            "                                                                                                  \n",
            " Encoder-5-MultiHeadSelfAttenti  (None, 512, 768)    0           ['Encoder-4-FeedForward-Norm[0][0\n",
            " on-Add (Add)                                                    ]',                              \n",
            "                                                                  'Encoder-5-MultiHeadSelfAttentio\n",
            "                                                                 n-Dropout[0][0]']                \n",
            "                                                                                                  \n",
            " Encoder-5-MultiHeadSelfAttenti  (None, 512, 768)    1536        ['Encoder-5-MultiHeadSelfAttentio\n",
            " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
            "                                                                                                  \n",
            " Encoder-5-FeedForward (FeedFor  (None, 512, 768)    4722432     ['Encoder-5-MultiHeadSelfAttentio\n",
            " ward)                                                           n-Norm[0][0]']                   \n",
            "                                                                                                  \n",
            " Encoder-5-FeedForward-Dropout   (None, 512, 768)    0           ['Encoder-5-FeedForward[0][0]']  \n",
            " (Dropout)                                                                                        \n",
            "                                                                                                  \n",
            " Encoder-5-FeedForward-Add (Add  (None, 512, 768)    0           ['Encoder-5-MultiHeadSelfAttentio\n",
            " )                                                               n-Norm[0][0]',                   \n",
            "                                                                  'Encoder-5-FeedForward-Dropout[0\n",
            "                                                                 ][0]']                           \n",
            "                                                                                                  \n",
            " Encoder-5-FeedForward-Norm (La  (None, 512, 768)    1536        ['Encoder-5-FeedForward-Add[0][0]\n",
            " yerNormalization)                                               ']                               \n",
            "                                                                                                  \n",
            " Encoder-6-MultiHeadSelfAttenti  (None, 512, 768)    2362368     ['Encoder-5-FeedForward-Norm[0][0\n",
            " on (MultiHeadAttention)                                         ]']                              \n",
            "                                                                                                  \n",
            " Encoder-6-MultiHeadSelfAttenti  (None, 512, 768)    0           ['Encoder-6-MultiHeadSelfAttentio\n",
            " on-Dropout (Dropout)                                            n[0][0]']                        \n",
            "                                                                                                  \n",
            " Encoder-6-MultiHeadSelfAttenti  (None, 512, 768)    0           ['Encoder-5-FeedForward-Norm[0][0\n",
            " on-Add (Add)                                                    ]',                              \n",
            "                                                                  'Encoder-6-MultiHeadSelfAttentio\n",
            "                                                                 n-Dropout[0][0]']                \n",
            "                                                                                                  \n",
            " Encoder-6-MultiHeadSelfAttenti  (None, 512, 768)    1536        ['Encoder-6-MultiHeadSelfAttentio\n",
            " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
            "                                                                                                  \n",
            " Encoder-6-FeedForward (FeedFor  (None, 512, 768)    4722432     ['Encoder-6-MultiHeadSelfAttentio\n",
            " ward)                                                           n-Norm[0][0]']                   \n",
            "                                                                                                  \n",
            " Encoder-6-FeedForward-Dropout   (None, 512, 768)    0           ['Encoder-6-FeedForward[0][0]']  \n",
            " (Dropout)                                                                                        \n",
            "                                                                                                  \n",
            " Encoder-6-FeedForward-Add (Add  (None, 512, 768)    0           ['Encoder-6-MultiHeadSelfAttentio\n",
            " )                                                               n-Norm[0][0]',                   \n",
            "                                                                  'Encoder-6-FeedForward-Dropout[0\n",
            "                                                                 ][0]']                           \n",
            "                                                                                                  \n",
            " Encoder-6-FeedForward-Norm (La  (None, 512, 768)    1536        ['Encoder-6-FeedForward-Add[0][0]\n",
            " yerNormalization)                                               ']                               \n",
            "                                                                                                  \n",
            " Encoder-7-MultiHeadSelfAttenti  (None, 512, 768)    2362368     ['Encoder-6-FeedForward-Norm[0][0\n",
            " on (MultiHeadAttention)                                         ]']                              \n",
            "                                                                                                  \n",
            " Encoder-7-MultiHeadSelfAttenti  (None, 512, 768)    0           ['Encoder-7-MultiHeadSelfAttentio\n",
            " on-Dropout (Dropout)                                            n[0][0]']                        \n",
            "                                                                                                  \n",
            " Encoder-7-MultiHeadSelfAttenti  (None, 512, 768)    0           ['Encoder-6-FeedForward-Norm[0][0\n",
            " on-Add (Add)                                                    ]',                              \n",
            "                                                                  'Encoder-7-MultiHeadSelfAttentio\n",
            "                                                                 n-Dropout[0][0]']                \n",
            "                                                                                                  \n",
            " Encoder-7-MultiHeadSelfAttenti  (None, 512, 768)    1536        ['Encoder-7-MultiHeadSelfAttentio\n",
            " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
            "                                                                                                  \n",
            " Encoder-7-FeedForward (FeedFor  (None, 512, 768)    4722432     ['Encoder-7-MultiHeadSelfAttentio\n",
            " ward)                                                           n-Norm[0][0]']                   \n",
            "                                                                                                  \n",
            " Encoder-7-FeedForward-Dropout   (None, 512, 768)    0           ['Encoder-7-FeedForward[0][0]']  \n",
            " (Dropout)                                                                                        \n",
            "                                                                                                  \n",
            " Encoder-7-FeedForward-Add (Add  (None, 512, 768)    0           ['Encoder-7-MultiHeadSelfAttentio\n",
            " )                                                               n-Norm[0][0]',                   \n",
            "                                                                  'Encoder-7-FeedForward-Dropout[0\n",
            "                                                                 ][0]']                           \n",
            "                                                                                                  \n",
            " Encoder-7-FeedForward-Norm (La  (None, 512, 768)    1536        ['Encoder-7-FeedForward-Add[0][0]\n",
            " yerNormalization)                                               ']                               \n",
            "                                                                                                  \n",
            " Encoder-8-MultiHeadSelfAttenti  (None, 512, 768)    2362368     ['Encoder-7-FeedForward-Norm[0][0\n",
            " on (MultiHeadAttention)                                         ]']                              \n",
            "                                                                                                  \n",
            " Encoder-8-MultiHeadSelfAttenti  (None, 512, 768)    0           ['Encoder-8-MultiHeadSelfAttentio\n",
            " on-Dropout (Dropout)                                            n[0][0]']                        \n",
            "                                                                                                  \n",
            " Encoder-8-MultiHeadSelfAttenti  (None, 512, 768)    0           ['Encoder-7-FeedForward-Norm[0][0\n",
            " on-Add (Add)                                                    ]',                              \n",
            "                                                                  'Encoder-8-MultiHeadSelfAttentio\n",
            "                                                                 n-Dropout[0][0]']                \n",
            "                                                                                                  \n",
            " Encoder-8-MultiHeadSelfAttenti  (None, 512, 768)    1536        ['Encoder-8-MultiHeadSelfAttentio\n",
            " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
            "                                                                                                  \n",
            " Encoder-8-FeedForward (FeedFor  (None, 512, 768)    4722432     ['Encoder-8-MultiHeadSelfAttentio\n",
            " ward)                                                           n-Norm[0][0]']                   \n",
            "                                                                                                  \n",
            " Encoder-8-FeedForward-Dropout   (None, 512, 768)    0           ['Encoder-8-FeedForward[0][0]']  \n",
            " (Dropout)                                                                                        \n",
            "                                                                                                  \n",
            " Encoder-8-FeedForward-Add (Add  (None, 512, 768)    0           ['Encoder-8-MultiHeadSelfAttentio\n",
            " )                                                               n-Norm[0][0]',                   \n",
            "                                                                  'Encoder-8-FeedForward-Dropout[0\n",
            "                                                                 ][0]']                           \n",
            "                                                                                                  \n",
            " Encoder-8-FeedForward-Norm (La  (None, 512, 768)    1536        ['Encoder-8-FeedForward-Add[0][0]\n",
            " yerNormalization)                                               ']                               \n",
            "                                                                                                  \n",
            " Encoder-9-MultiHeadSelfAttenti  (None, 512, 768)    2362368     ['Encoder-8-FeedForward-Norm[0][0\n",
            " on (MultiHeadAttention)                                         ]']                              \n",
            "                                                                                                  \n",
            " Encoder-9-MultiHeadSelfAttenti  (None, 512, 768)    0           ['Encoder-9-MultiHeadSelfAttentio\n",
            " on-Dropout (Dropout)                                            n[0][0]']                        \n",
            "                                                                                                  \n",
            " Encoder-9-MultiHeadSelfAttenti  (None, 512, 768)    0           ['Encoder-8-FeedForward-Norm[0][0\n",
            " on-Add (Add)                                                    ]',                              \n",
            "                                                                  'Encoder-9-MultiHeadSelfAttentio\n",
            "                                                                 n-Dropout[0][0]']                \n",
            "                                                                                                  \n",
            " Encoder-9-MultiHeadSelfAttenti  (None, 512, 768)    1536        ['Encoder-9-MultiHeadSelfAttentio\n",
            " on-Norm (LayerNormalization)                                    n-Add[0][0]']                    \n",
            "                                                                                                  \n",
            " Encoder-9-FeedForward (FeedFor  (None, 512, 768)    4722432     ['Encoder-9-MultiHeadSelfAttentio\n",
            " ward)                                                           n-Norm[0][0]']                   \n",
            "                                                                                                  \n",
            " Encoder-9-FeedForward-Dropout   (None, 512, 768)    0           ['Encoder-9-FeedForward[0][0]']  \n",
            " (Dropout)                                                                                        \n",
            "                                                                                                  \n",
            " Encoder-9-FeedForward-Add (Add  (None, 512, 768)    0           ['Encoder-9-MultiHeadSelfAttentio\n",
            " )                                                               n-Norm[0][0]',                   \n",
            "                                                                  'Encoder-9-FeedForward-Dropout[0\n",
            "                                                                 ][0]']                           \n",
            "                                                                                                  \n",
            " Encoder-9-FeedForward-Norm (La  (None, 512, 768)    1536        ['Encoder-9-FeedForward-Add[0][0]\n",
            " yerNormalization)                                               ']                               \n",
            "                                                                                                  \n",
            " Encoder-10-MultiHeadSelfAttent  (None, 512, 768)    2362368     ['Encoder-9-FeedForward-Norm[0][0\n",
            " ion (MultiHeadAttention)                                        ]']                              \n",
            "                                                                                                  \n",
            " Encoder-10-MultiHeadSelfAttent  (None, 512, 768)    0           ['Encoder-10-MultiHeadSelfAttenti\n",
            " ion-Dropout (Dropout)                                           on[0][0]']                       \n",
            "                                                                                                  \n",
            " Encoder-10-MultiHeadSelfAttent  (None, 512, 768)    0           ['Encoder-9-FeedForward-Norm[0][0\n",
            " ion-Add (Add)                                                   ]',                              \n",
            "                                                                  'Encoder-10-MultiHeadSelfAttenti\n",
            "                                                                 on-Dropout[0][0]']               \n",
            "                                                                                                  \n",
            " Encoder-10-MultiHeadSelfAttent  (None, 512, 768)    1536        ['Encoder-10-MultiHeadSelfAttenti\n",
            " ion-Norm (LayerNormalization)                                   on-Add[0][0]']                   \n",
            "                                                                                                  \n",
            " Encoder-10-FeedForward (FeedFo  (None, 512, 768)    4722432     ['Encoder-10-MultiHeadSelfAttenti\n",
            " rward)                                                          on-Norm[0][0]']                  \n",
            "                                                                                                  \n",
            " Encoder-10-FeedForward-Dropout  (None, 512, 768)    0           ['Encoder-10-FeedForward[0][0]'] \n",
            "  (Dropout)                                                                                       \n",
            "                                                                                                  \n",
            " Encoder-10-FeedForward-Add (Ad  (None, 512, 768)    0           ['Encoder-10-MultiHeadSelfAttenti\n",
            " d)                                                              on-Norm[0][0]',                  \n",
            "                                                                  'Encoder-10-FeedForward-Dropout[\n",
            "                                                                 0][0]']                          \n",
            "                                                                                                  \n",
            " Encoder-10-FeedForward-Norm (L  (None, 512, 768)    1536        ['Encoder-10-FeedForward-Add[0][0\n",
            " ayerNormalization)                                              ]']                              \n",
            "                                                                                                  \n",
            " Encoder-11-MultiHeadSelfAttent  (None, 512, 768)    2362368     ['Encoder-10-FeedForward-Norm[0][\n",
            " ion (MultiHeadAttention)                                        0]']                             \n",
            "                                                                                                  \n",
            " Encoder-11-MultiHeadSelfAttent  (None, 512, 768)    0           ['Encoder-11-MultiHeadSelfAttenti\n",
            " ion-Dropout (Dropout)                                           on[0][0]']                       \n",
            "                                                                                                  \n",
            " Encoder-11-MultiHeadSelfAttent  (None, 512, 768)    0           ['Encoder-10-FeedForward-Norm[0][\n",
            " ion-Add (Add)                                                   0]',                             \n",
            "                                                                  'Encoder-11-MultiHeadSelfAttenti\n",
            "                                                                 on-Dropout[0][0]']               \n",
            "                                                                                                  \n",
            " Encoder-11-MultiHeadSelfAttent  (None, 512, 768)    1536        ['Encoder-11-MultiHeadSelfAttenti\n",
            " ion-Norm (LayerNormalization)                                   on-Add[0][0]']                   \n",
            "                                                                                                  \n",
            " Encoder-11-FeedForward (FeedFo  (None, 512, 768)    4722432     ['Encoder-11-MultiHeadSelfAttenti\n",
            " rward)                                                          on-Norm[0][0]']                  \n",
            "                                                                                                  \n",
            " Encoder-11-FeedForward-Dropout  (None, 512, 768)    0           ['Encoder-11-FeedForward[0][0]'] \n",
            "  (Dropout)                                                                                       \n",
            "                                                                                                  \n",
            " Encoder-11-FeedForward-Add (Ad  (None, 512, 768)    0           ['Encoder-11-MultiHeadSelfAttenti\n",
            " d)                                                              on-Norm[0][0]',                  \n",
            "                                                                  'Encoder-11-FeedForward-Dropout[\n",
            "                                                                 0][0]']                          \n",
            "                                                                                                  \n",
            " Encoder-11-FeedForward-Norm (L  (None, 512, 768)    1536        ['Encoder-11-FeedForward-Add[0][0\n",
            " ayerNormalization)                                              ]']                              \n",
            "                                                                                                  \n",
            " Encoder-12-MultiHeadSelfAttent  (None, 512, 768)    2362368     ['Encoder-11-FeedForward-Norm[0][\n",
            " ion (MultiHeadAttention)                                        0]']                             \n",
            "                                                                                                  \n",
            " Encoder-12-MultiHeadSelfAttent  (None, 512, 768)    0           ['Encoder-12-MultiHeadSelfAttenti\n",
            " ion-Dropout (Dropout)                                           on[0][0]']                       \n",
            "                                                                                                  \n",
            " Encoder-12-MultiHeadSelfAttent  (None, 512, 768)    0           ['Encoder-11-FeedForward-Norm[0][\n",
            " ion-Add (Add)                                                   0]',                             \n",
            "                                                                  'Encoder-12-MultiHeadSelfAttenti\n",
            "                                                                 on-Dropout[0][0]']               \n",
            "                                                                                                  \n",
            " Encoder-12-MultiHeadSelfAttent  (None, 512, 768)    1536        ['Encoder-12-MultiHeadSelfAttenti\n",
            " ion-Norm (LayerNormalization)                                   on-Add[0][0]']                   \n",
            "                                                                                                  \n",
            " Encoder-12-FeedForward (FeedFo  (None, 512, 768)    4722432     ['Encoder-12-MultiHeadSelfAttenti\n",
            " rward)                                                          on-Norm[0][0]']                  \n",
            "                                                                                                  \n",
            " Encoder-12-FeedForward-Dropout  (None, 512, 768)    0           ['Encoder-12-FeedForward[0][0]'] \n",
            "  (Dropout)                                                                                       \n",
            "                                                                                                  \n",
            " Encoder-12-FeedForward-Add (Ad  (None, 512, 768)    0           ['Encoder-12-MultiHeadSelfAttenti\n",
            " d)                                                              on-Norm[0][0]',                  \n",
            "                                                                  'Encoder-12-FeedForward-Dropout[\n",
            "                                                                 0][0]']                          \n",
            "                                                                                                  \n",
            " Encoder-12-FeedForward-Norm (L  (None, 512, 768)    1536        ['Encoder-12-FeedForward-Add[0][0\n",
            " ayerNormalization)                                              ]']                              \n",
            "                                                                                                  \n",
            " Extract (Extract)              (None, 768)          0           ['Encoder-12-FeedForward-Norm[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " NSP-Dense (Dense)              (None, 768)          590592      ['Extract[0][0]']                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 3)            2307        ['NSP-Dense[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 177,855,747\n",
            "Trainable params: 177,855,747\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BD7w-zOAVlK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMErFqfKf8Wc"
      },
      "source": [
        "learner = ktrain.get_learner(model = model , train_data=(X_train , y_train),\n",
        "                             val_data = (X_test , y_test),\n",
        "                             batch_size = 6)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upLLAnufY4Ok",
        "outputId": "b02a5dcf-fd86-4a7d-d54c-a123b9712970"
      },
      "source": [
        "learner.fit(5e-3, 2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMCIlBiXgHOs",
        "outputId": "19d6c3c3-337c-4f76-a000-c9f37168d2f4"
      },
      "source": [
        "#learner.lr_find()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "simulating training for different learning rates... this may take a few moments...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANs1bzH4gOkn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "7b9081d1-d66c-4f4e-8012-67845a4c2ba8"
      },
      "source": [
        "learner.lr_plot()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XdfYcJU1LM0X",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0e0b6cb7-e672-46d2-d287-f33c6ebf631b"
      },
      "source": [
        "#learner.fit_onecycle(lr=10**-5, epochs=1, class_weight=weights)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "begin training using onecycle policy with max lr of 1e-05...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-2bfea67cea7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_onecycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ktrain/core.py\u001b[0m in \u001b[0;36mfit_onecycle\u001b[0;34m(self, lr, epochs, checkpoint_folder, cycle_momentum, max_momentum, min_momentum, class_weight, callbacks, steps_per_epoch, verbose)\u001b[0m\n\u001b[1;32m    899\u001b[0m                         \u001b[0mcheckpoint_folder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint_folder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m                         \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m                         steps_per_epoch=steps_per_epoch)\n\u001b[0m\u001b[1;32m    902\u001b[0m         \u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m         \u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'iterations'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'iterations'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ktrain/core.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, lr, n_cycles, cycle_len, cycle_mult, lr_decay, checkpoint_folder, early_stopping, verbose, class_weight, callbacks, steps_per_epoch)\u001b[0m\n\u001b[1;32m   1180\u001b[0m                                   \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m                                   \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m                                   callbacks=kcallbacks)\n\u001b[0m\u001b[1;32m   1183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msgdr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msgdr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m:  failed to allocate memory\n\t [[node model_1/Encoder-10-MultiHeadSelfAttention-Norm/Square\n (defined at /usr/local/lib/python3.7/dist-packages/keras/backend.py:2661)\n]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_69400]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node model_1/Encoder-10-MultiHeadSelfAttention-Norm/Square:\nIn[0] model_1/Encoder-10-MultiHeadSelfAttention-Norm/sub (defined at /usr/local/lib/python3.7/dist-packages/keras_layer_normalization/layer_normalization.py:91)\n\nOperation defined at: (most recent call last)\n>>>   File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n>>>     \"__main__\", mod_spec)\n>>> \n>>>   File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n>>>     exec(code, run_globals)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n>>>     app.launch_new_instance()\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n>>>     app.start()\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n>>>     self.io_loop.start()\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n>>>     self.asyncio_loop.run_forever()\n>>> \n>>>   File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n>>>     self._run_once()\n>>> \n>>>   File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n>>>     handle._run()\n>>> \n>>>   File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n>>>     self._context.run(self._callback, *self._args)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n>>>     handler_func(fileobj, events)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 452, in _handle_events\n>>>     self._handle_recv()\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 481, in _handle_recv\n>>>     self._run_callback(callback, msg)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 431, in _run_callback\n>>>     callback(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n>>>     return self.dispatch_shell(stream, msg)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n>>>     handler(stream, idents, msg)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n>>>     user_expressions, allow_stdin)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n>>>     res = shell.run_cell(code, store_history=store_history, silent=silent)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n>>>     return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n>>>     interactivity=interactivity, compiler=compiler, result=result)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2828, in run_ast_nodes\n>>>     if self.run_code(code, result):\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n>>>     exec(code_obj, self.user_global_ns, self.user_ns)\n>>> \n>>>   File \"<ipython-input-38-80c7fb0d481a>\", line 1, in <module>\n>>>     learner.fit_onecycle(lr=10**-6, epochs=1, class_weight=weights)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ktrain/core.py\", line 901, in fit_onecycle\n>>>     steps_per_epoch=steps_per_epoch)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/ktrain/core.py\", line 1182, in fit\n>>>     callbacks=kcallbacks)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1216, in fit\n>>>     tmp_logs = self.train_function(iterator)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 878, in train_function\n>>>     return step_function(self, iterator)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 867, in step_function\n>>>     outputs = model.distribute_strategy.run(run_step, args=(data,))\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 860, in run_step\n>>>     outputs = model.train_step(data)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 808, in train_step\n>>>     y_pred = self(x, training=True)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\", line 452, in call\n>>>     inputs, training=training, mask=mask)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py\", line 589, in _run_internal_graph\n>>>     outputs = node.layer(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\", line 1083, in __call__\n>>>     outputs = call_fn(inputs, *args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 92, in error_handler\n>>>     return fn(*args, **kwargs)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras_layer_normalization/layer_normalization.py\", line 91, in call\n>>>     variance = K.mean(K.square(inputs - mean), axis=-1, keepdims=True)\n>>> \n>>>   File \"/usr/local/lib/python3.7/dist-packages/keras/backend.py\", line 2661, in square\n>>>     return tf.square(x)\n>>> "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bR0nszULa2d"
      },
      "source": [
        "# predictor = ktrain.get_predictor(learner.model, preproc)\n",
        "# predictor.save('/content/drive/My Drive/bert')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "sLo0aXoGLbwS",
        "outputId": "77be3f9c-aac2-4f5b-a85a-2b42a2eeda8d"
      },
      "source": [
        "test_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>9661</th>\n",
              "      <td>আওয়ামীলীগের মত গোষ্ঠীর সাথে একাত্বতা পোষণ না ক...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9662</th>\n",
              "      <td>যারা মাশরাফিকে ভালোবাসে কিন্তু তার আওয়ামী লিগে...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9663</th>\n",
              "      <td>বিএনপি যে নাহ সেতাই বড় ভালো বিষয়</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9664</th>\n",
              "      <td>মাশরাফি কি আমাদের কাছে শচীন টেন্ডুলকার বা ম্যা...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9665</th>\n",
              "      <td>মি. কেপ্টেইন, আপনি ক্রিকেট ও খেলবেন এম পি ও হব...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   data  label\n",
              "9661  আওয়ামীলীগের মত গোষ্ঠীর সাথে একাত্বতা পোষণ না ক...      0\n",
              "9662  যারা মাশরাফিকে ভালোবাসে কিন্তু তার আওয়ামী লিগে...      0\n",
              "9663                   বিএনপি যে নাহ সেতাই বড় ভালো বিষয়      1\n",
              "9664  মাশরাফি কি আমাদের কাছে শচীন টেন্ডুলকার বা ম্যা...      1\n",
              "9665  মি. কেপ্টেইন, আপনি ক্রিকেট ও খেলবেন এম পি ও হব...      1"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHH6gq7TLjS2"
      },
      "source": [
        "content = df_test['data'].tolist()\n",
        "labels = df_test['label'].tolist()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PjaNa7RLwfm"
      },
      "source": [
        "import re\n",
        "def rex(token):\n",
        "  return re.sub(\"([A-Za-z0-9_:.]+|[\\n]+|[\\xa0]+|শেয়ার করুন,)\",\"\",token)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNiVQowjL4KW"
      },
      "source": [
        "test =[rex(token) for token in content]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLahKIu8MA8h"
      },
      "source": [
        "pred = predictor.predict(test)\n",
        "# pred= labeling(pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-ydjedcMZoN"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confusion_matrix(labels, pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqJ-oBYsMakV"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "target_names = ['1', '0','2']\n",
        "print(classification_report(labels , pred ,target_names = target_names ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiaKYXoAL7EI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}